# PR-17 Mandate — Query Latency Benchmark

## Objective
Measure and document **query latency** for `events_list_range` across realistic usage windows (day, week, month) on datasets of 10k events.  
Establish baseline P50/P95 timings and publish them as reference for future regression checks.

---

## Scope
- **Benchmark Harness:**
  - Extend or add a CLI command (e.g., `time query-bench`) that executes `events_list_range` with varying time windows.
  - Parameters: household ID, window size (day/week/month), dataset size, iterations.
- **Fixtures:**
  - Use synthetic datasets with 10k seeded events, including recurrences and EXDATEs, to mimic real-world load.
  - Place fixture generation under `/scripts/bench/generate_query_fixture.ts`.
- **Metrics:**
  - Capture response times (ms) for each query.
  - Aggregate results: P50, P95, min, max.
  - Log results in machine-readable (JSON) and human-readable formats.
- **Baseline Documentation:**
  - Store results in `/docs/query-performance.md` including:
    - Dataset parameters.
    - Query window sizes.
    - Latency table (P50/P95/min/max).
    - Hardware spec and date of run.

---

## Non-Goals
- No query optimisation in this PR (measurement only).  
- No recurrence correctness changes — handled elsewhere.  
- No UI or IPC surface modifications.  

---

## Acceptance Criteria
1. **Harness:** CLI tool runs `events_list_range` with day/week/month windows.  
2. **Dataset Size:** Benchmarked with 10k events, results recorded.  
3. **Metrics:** Logs include P50, P95, min, max latencies.  
4. **Baseline Doc:** `/docs/query-performance.md` contains clear tables and context.  
5. **Repeatability:** Running benchmark twice with same dataset produces results within ±10%.  
6. **CI Smoke Run:** Small-scale (1k dataset, 10 queries) run in CI, verifying harness works but not enforcing thresholds.  

---

## Evidence Required in PR
- **CLI Run Logs:** Sample output showing latency distribution for day/week/month windows.  
- **Baseline Doc Proof:** `/docs/query-performance.md` committed with full tables.  
- **Fixture Proof:** Snippet from fixture generation script showing deterministic data.  
- **Repeatability Demo:** Two runs on same hardware with near-identical results.  
- **CI Proof:** Screenshot/log of smoke test running successfully.  

---

## Rollback Plan
- Remove `time query-bench` CLI tool.  
- Delete fixture generator script.  
- Remove `/docs/query-performance.md`.  
- Leaves query logic untouched but without latency benchmarks.  

---

## PR Title / Description
- **Title:** `perf(query): add events_list_range latency benchmark and publish baseline results`  
- **Body:** Must include Objective, Scope, Non-Goals, Acceptance Criteria, Evidence, and Rollback.

---
```
