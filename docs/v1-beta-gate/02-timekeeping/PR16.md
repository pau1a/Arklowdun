# PR-16 Mandate — Backfill Throughput Benchmark

## Objective
Introduce reproducible **performance benchmarks** for timezone backfill to measure throughput (rows/sec) and ensure the process scales to large datasets (10k–100k events).  
Record baseline metrics and provide a foundation for regression detection in later work.

---

## Scope
- **Benchmark Harness:**
  - Add a dedicated CLI subcommand (e.g., `time backfill-bench`) that runs backfill against synthetic or fixture datasets.
  - Configurable parameters: dataset size, chunk size, default timezone, and dry-run mode.
- **Fixtures:**
  - Provide deterministic synthetic datasets of 10k and 100k events, seeded with a mix of timed and all-day events.
  - Store fixture generation script in `/scripts/bench/generate_backfill_fixture.ts` (or equivalent).
- **Metrics:**
  - Record rows scanned, updated, skipped, elapsed time, throughput (rows/sec).
  - Collect per-chunk timing for variance analysis.
- **Baseline Documentation:**
  - Publish results in `/docs/backfill-performance.md` including:
    - Hardware spec (CPU, RAM, OS).
    - Date of run.
    - Dataset size.
    - Results table (rows/sec, avg chunk time).
    - Observations (bottlenecks, anomalies).

---

## Non-Goals
- No optimisations to backfill algorithm — this PR is **measurement-only**.  
- No recurrence expansion benchmarking (covered in PR-9).  
- No user-facing UI changes — this is for developer/operator validation.  

---

## Acceptance Criteria
1. **Benchmark Tool:** CLI command runs successfully on fixture DBs and produces detailed logs.  
2. **10k Dataset:** Benchmarked, throughput measured, results published.  
3. **100k Dataset:** Benchmarked, throughput measured, results published.  
4. **Variance Reporting:** Per-chunk timing recorded and logged.  
5. **Baseline Doc:** `/docs/backfill-performance.md` contains results, tables, and context.  
6. **Repeatability:** Running the benchmark twice with same params produces similar throughput (±10%).  
7. **CI Smoke Check:** Lightweight CI job runs a tiny (1k) backfill to verify harness works, not for performance gating.  

---

## Evidence Required in PR
- **CLI Run Logs:** Excerpts showing throughput numbers for 10k and 100k datasets.  
- **Baseline Doc Proof:** `/docs/backfill-performance.md` included with metrics tables.  
- **Fixture Proof:** Snippet from fixture generation script showing deterministic event seed.  
- **Variance Demo:** Log excerpt showing per-chunk timings.  
- **CI Proof:** Passing run of smoke check job with 1k dataset.  

---

## Rollback Plan
- Remove `time backfill-bench` CLI command.  
- Delete benchmark fixtures and generator script.  
- Remove `/docs/backfill-performance.md`.  
- Leaves backfill functional, but no benchmark tooling.  

---

## PR Title / Description
- **Title:** `perf(backfill): add throughput benchmark harness and publish baseline results`  
- **Body:** Must include Objective, Scope, Non-Goals, Acceptance Criteria, Evidence, and Rollback.

---
```
