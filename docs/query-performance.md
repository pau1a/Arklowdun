# events_list_range query latency benchmark

This document tracks baseline performance for the `time query-bench` harness that measures `events_list_range` latency across representative calendar windows (day, week, month). The goal is to provide a repeatable reference point for regression detection when the calendar command surface evolves.

## Fixture dataset

The benchmark uses deterministic SQLite fixtures generated by `scripts/bench/generate_query_fixture.ts`. The generator seeds 10k events that mix timed sessions, all-day blocks, recurring series, and UTC-only recurrences with EXDATEs using a fixed Mulberry32 seed so repeated runs produce identical data unless parameters change.【F:scripts/bench/generate_query_fixture.ts†L5-L367】

```ts
const DEFAULT_ROWS = 10_000;
const DEFAULT_SEED = 104729; // prime seed for deterministic spread
// ...
const rand = mulberry32(opts.seed);
```

A 10k-row fixture is stored at `fixtures/time/query/query-10k.sqlite3`. The CLI validates that the seeded household exists and reports aggregate counts (10 000 events, 2 987 recurrences, 498 series with EXDATEs) before executing queries.【F:src-tauri/scripts/time_backfill.rs†L489-L757】【5d15b2†L1-L16】 Regenerating the dataset is a single command:

```sh
node --loader ts-node/esm scripts/bench/generate_query_fixture.ts --rows 10000
```

The same generator can produce lighter datasets (e.g., 1k rows) for CI smoke checks.【d0daa3†L1-L34】

## Harness usage

The `time` maintenance binary exposes a `query-bench` subcommand that loads a fixture into a temporary database, randomises daily start offsets, and records latency samples for each requested window. Key parameters include the fixture size (`--rows`), number of timed iterations, warmup count, PRNG seed, and window list (day/week/month via clap `ValueEnum`).【F:src-tauri/scripts/time_backfill.rs†L108-L757】 Each window aggregates min, P50, P95, max, mean latency, item counts, truncation frequency, and the sampled date range before emitting a JSON summary for downstream tooling.【F:src-tauri/scripts/time_backfill.rs†L702-L776】

The baseline command used for the measurements below was:

```sh
(cd src-tauri && cargo run --locked --bin time -- \
  query-bench --rows 10000 --iterations 200 --warmup 5 \
  --window day --window week --window month)
```

## Environment

Benchmarks were executed inside the GitHub Codespaces container (Ubuntu 6.12 kernel) on an Intel Xeon Platinum 8272CL (5 vCPUs) at the noted timestamp.【f6a7ae†L1-L2】【78d0cb†L1-L41】【548d15†L1-L2】

| Field | Value |
| --- | --- |
| Date (UTC) | 2025-09-21 09:45 |
| CPU | Intel(R) Xeon(R) Platinum 8272CL @ 2.60 GHz (5 vCPUs) |
| Kernel | Linux 6.12.13 (Codespaces container) |

## Baseline results (10k events)

After a cold start warm-up, the second 10k run serves as the baseline reference. Each window executed 5 warmup iterations followed by 200 timed samples (600 total queries), producing the following latencies in milliseconds.【5d15b2†L1-L29】

| Window | Duration | Min | P50 | P95 | Max | Mean | Avg items | Truncated |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Day | 1 day | 243.85 | 356.67 | 454.81 | 495.82 | 353.74 | 339 | 0 |
| Week | 7 days | 256.28 | 358.60 | 457.72 | 503.96 | 364.71 | 2 077 | 0 |
| Month | 30 days | 307.16 | 455.45 | 569.42 | 654.57 | 455.02 | 8 829 | 133 |

Notes:

- Dataset coverage spans 160 days (2024‑01‑21 → 2024‑06‑29) and returns up to 10k items per query, so the month window deliberately exercises truncation behaviour under heavy recurrence expansion.【5d15b2†L1-L21】
- JSON output is printed alongside human-readable metrics for machine ingestion; store or diff it to spot regressions.【5d15b2†L29-L34】

## Repeatability check

Re-running the benchmark immediately afterwards yielded latency distributions within ±6% of the baseline for both P50 and P95 across all windows, satisfying the ±10% stability target.【5d15b2†L1-L34】【1887bb†L1-L34】 Key comparisons:

- **Day window:** 356.67 ms → 349.41 ms (‑2.0% P50), 454.81 ms → 444.49 ms (‑2.3% P95).
- **Week window:** 358.60 ms → 362.71 ms (+1.1% P50), 457.72 ms → 483.16 ms (+5.6% P95).
- **Month window:** 455.45 ms → 464.57 ms (+2.0% P50), 569.42 ms → 604.66 ms (+6.2% P95).

The JSON summaries printed at the end of each run can be archived for regression diffing; all totals (rows, recurrences, truncations) match between runs.【5d15b2†L29-L34】【1887bb†L8-L32】

## CI smoke test

`npm run bench:query:smoke` rebuilds the 1k-row fixture and runs ten queries per window (two warmups) to ensure the harness remains runnable in CI. The sample output below confirms the end-to-end flow, including JSON emission.【d0daa3†L1-L44】

```
Window: day (86400000 ms)
  Latency (ms): min 29.46 | p50 35.10 | p95 48.79 | max 49.87
Window: week (604800000 ms)
  Latency (ms): min 30.12 | p50 38.67 | p95 47.65 | max 48.15
Window: month (2592000000 ms)
  Latency (ms): min 40.55 | p50 53.61 | p95 69.60 | max 70.46
```

Store these results with benchmark runs when updating the fixture or query planner so regressions can be caught early.
